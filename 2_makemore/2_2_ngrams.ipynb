{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fpath = './data/names.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(data_fpath, 'r') as f:\n",
    "    words = f.read().splitlines()\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min len: 2; max len: 15\n"
     ]
    }
   ],
   "source": [
    "word_lens = [len(word) for word in words]\n",
    "print(f'min len: {min(word_lens)}; max len: {max(word_lens)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ngram model as an array with counts\n",
    "using generalized version for ngrams given arbitrary n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEP_TOK = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('n', '.', '.'), 6763),\n",
       " (('a', '.', '.'), 6640),\n",
       " (('.', '.', 'a'), 4410),\n",
       " (('e', '.', '.'), 3983),\n",
       " (('.', '.', 'k'), 2963),\n",
       " (('.', '.', 'm'), 2538),\n",
       " (('i', '.', '.'), 2489),\n",
       " (('.', '.', 'j'), 2422),\n",
       " (('h', '.', '.'), 2409),\n",
       " (('.', '.', 's'), 2055)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_dict = {}\n",
    "for word in words:\n",
    "    chars = [SEP_TOK]*(n-1) + list(word) + [SEP_TOK]*(n-1)\n",
    "    ngram_chars = [chars[i:] for i in range(n)]\n",
    "    for ngram in zip(*ngram_chars):\n",
    "        ngrams_dict[ngram] = ngrams_dict.get(ngram, 0) + 1\n",
    "ngrams_dict = sorted(ngrams_dict.items(), key=lambda kv: kv[1], reverse=True)\n",
    "ngrams_dict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [SEP_TOK] + sorted(list(set(''.join(words))))\n",
    "stoi = {s: i for i, s in enumerate(vocab)}\n",
    "itos = {i: s for i, s in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 155/32033 [00:00<00:40, 792.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32033/32033 [00:24<00:00, 1303.09it/s]\n"
     ]
    }
   ],
   "source": [
    "N = torch.zeros([len(vocab) for _ in range(n)], dtype=torch.int32)\n",
    "for word in tqdm(words):\n",
    "    chars = [SEP_TOK]*(n-1) + list(word) + [SEP_TOK]*(n-1)\n",
    "    ngram_chars = [chars[i:] for i in range(n)]\n",
    "    for ngram in zip(*ngram_chars):\n",
    "        ixs = tuple(stoi[ch] for ch in ngram)\n",
    "        N[ixs] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_count = 0 # smooths the probabilities\n",
    "P = (N+base_count).float()\n",
    "P = P / P.sum(axis=(n-1), keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide\n",
      "jakasid\n",
      "prelay\n",
      "adin\n",
      "kairritoper\n",
      "sathen\n",
      "sameia\n",
      "yanileniassibiainewin\n",
      "lessiyanayla\n",
      "te\n",
      "farmanthya\n",
      "demmer\n",
      "finslena\n",
      "jaylicore\n",
      "ya\n",
      "jocken\n",
      "jamilyn\n",
      "korin\n",
      "wyn\n",
      "ne\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "n_samples = 20\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for _ in range(n_samples):\n",
    "    ixs = deque([stoi[SEP_TOK]] * (n-1))\n",
    "    out = []\n",
    "    while True:\n",
    "        prob_distr = P[tuple(ixs)]\n",
    "        ix = torch.multinomial(prob_distr, num_samples=1, replacement=True, generator=g).item()\n",
    "        if ix == stoi[SEP_TOK]:\n",
    "            break\n",
    "        ixs.popleft()\n",
    "        ixs.append(ix)\n",
    "        out.append(itos[ix])\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 32033/32033 [00:17<00:00, 1844.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_likelihood=tensor(-505260.7500)\n",
      "nll=tensor(505260.7500)\n",
      "nll/count=tensor(1.9420)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "log_likelihood = 0.0\n",
    "count = 0\n",
    "for word in tqdm(words, 'Evaluating'):\n",
    "    chars = [SEP_TOK]*(n-1) + list(word) + [SEP_TOK]*(n-1)\n",
    "    ngram_chars = [chars[i:] for i in range(n)]\n",
    "    for ngram in zip(*ngram_chars):\n",
    "        ixs = tuple(stoi[ch] for ch in ngram)\n",
    "        prob = P[ixs]\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelihood += logprob\n",
    "        count += 1\n",
    "\n",
    "print(f'{log_likelihood=}')\n",
    "nll = -log_likelihood\n",
    "print(f'{nll=}')\n",
    "print(f'{nll/count=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ngram model as neural net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 3-gram samples:   0%|          | 0/32033 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 3-gram samples: 100%|██████████| 32033/32033 [00:01<00:00, 18923.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 260179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# creating the training set of bigrams\n",
    "xs, ys = [], []\n",
    "for word in tqdm(words, f'Creating {n}-gram samples'):\n",
    "    chars = [SEP_TOK]*(n-1) + list(word) + [SEP_TOK]*(n-1)\n",
    "    ngram_chars = [chars[i:] for i in range(n)]\n",
    "    for ngram in zip(*ngram_chars):\n",
    "        ixs = [stoi[ch] for ch in ngram]\n",
    "        xs.append(ixs[:-1])\n",
    "        ys.append(ixs[-1])\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "print(f'Number of training examples: {xs.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(xs, ys, W, weight_decay=1e-4):\n",
    "    logits = W[[x for x in xs.T]]\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "    # loss = average negative log likelihood\n",
    "    loss = -probs[torch.arange(len(ys)), ys].log().mean() + weight_decay*(W**2).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the \"model\"\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn(tuple(len(vocab) for _ in range(n)), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10th epoch, tr_loss=2.722\n",
      " 20th epoch, tr_loss=2.479\n",
      " 30th epoch, tr_loss=2.362\n",
      " 40th epoch, tr_loss=2.291\n",
      " 50th epoch, tr_loss=2.240\n",
      " 60th epoch, tr_loss=2.202\n",
      " 70th epoch, tr_loss=2.173\n",
      " 80th epoch, tr_loss=2.149\n",
      " 90th epoch, tr_loss=2.129\n",
      "100th epoch, tr_loss=2.113\n",
      "110th epoch, tr_loss=2.099\n",
      "120th epoch, tr_loss=2.087\n",
      "130th epoch, tr_loss=2.076\n",
      "140th epoch, tr_loss=2.067\n",
      "150th epoch, tr_loss=2.059\n",
      "160th epoch, tr_loss=2.052\n",
      "170th epoch, tr_loss=2.045\n",
      "180th epoch, tr_loss=2.039\n",
      "190th epoch, tr_loss=2.034\n",
      "200th epoch, tr_loss=2.029\n"
     ]
    }
   ],
   "source": [
    "for ep in range(200):\n",
    "    # forward pass\n",
    "    tr_loss = calc_loss(xs, ys, W, 0)\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None\n",
    "    tr_loss.backward()\n",
    "\n",
    "    # update\n",
    "    W.data += -100 * W.grad\n",
    "\n",
    "    if ep % 10 == 9:\n",
    "        print(f'{ep+1:>3}th epoch, tr_loss={tr_loss.item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide\n",
      "janaqah\n",
      "prelay\n",
      "adin\n",
      "kairritonian\n",
      "juwa\n",
      "kalinaaryanileniassdbyainrwibel\n",
      "se\n",
      "siely\n",
      "arte\n",
      "faveumtrifoetumj\n",
      "phyashiah\n",
      "jaylicora\n",
      "ya\n",
      "jocfpypjtbdmwebemikim\n",
      "yfvn\n",
      "anaasnhmvfjfopszxhxdgorfmxtdnvic\n",
      "le\n",
      "paun\n",
      "tyde\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "n_samples = 20\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for _ in range(n_samples):\n",
    "    ixs = deque([stoi[SEP_TOK]] * (n-1))\n",
    "    out = []\n",
    "    while True:\n",
    "        logits = W[tuple(ixs)]\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum()\n",
    "        ix = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
    "        if ix == stoi[SEP_TOK]:\n",
    "            break\n",
    "        ixs.popleft()\n",
    "        ixs.append(ix)\n",
    "        out.append(itos[ix])\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
